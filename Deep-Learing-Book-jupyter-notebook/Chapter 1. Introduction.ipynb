{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1:  \n",
    "+ 고대 그리스 시대부터 사람들은 생각하는 기계를 만드는 것을 꿈 꿔 왔다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p2:  \n",
    "+ 마찬가지로, 프로그래밍 가능한 컴퓨터가 등장한 후 사람들은 기계가 지능화 될 수 있을지 궁금해 하면서 노동을 자동화 하고, 사람의 말이나 사진을 이해하고, 의학 진단을 내리는 등의 지능형 소프트웨어를 찾기 시작했다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p3:\n",
    "+ 초기의 컴퓨터는 단순히 수학적 규칙이 있는 문제들을 사람보다 빠르게 푸는 것 으로 그 기능을 다 했다\n",
    "+ 컴퓨터의 인공지능의 목적은 사람이 수행하기는 쉽지만 설명은 어려운 문제들을 해결 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4:\n",
    "+ 이 책은 컴퓨터의 인공지능에 대한 도전을 다루었으며, concept를 통해 학습하고, 각 concept가 더 단순한 다른 cencept와 관련이 있다는 것을 배움으로써 세상을 이해할 수 있다는 솔루션을 제공한다.\n",
    "+ 컴퓨터는 학습이라는 방법을 이용해 스스로 concept 구조를 계층적으로 형성하며, 간단한 concept으로 복잡한 concept을 만들 수 있다.\n",
    "+ 계층화된 concept의 깊이는 아래로 깊어지는 결과를 가져오며, 이러한 인공지는 접근법을 deep learning 이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p5:\n",
    "+ 1997년 컴퓨터는 체스 챔피언을 쓰러트렸지만, 체스의 규칙은 간단한 전략(체스 말의 움직임)들로 완벽하게 설명 되므로, 프로그래머가 그러한 규칙을 쉽게 제공할 수 있다. (규칙 기반이라는 뜻)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p6:\n",
    "+ 사람과 다르게 컴퓨터는 공식(수학적 모델)이 있는 작업을 아쉬 쉽게 수행할 수 있다.\n",
    "+ 하지만 컴퓨터는 물체의 설명이나 연설을 하기에는 공식이 존재하지 않기 때문에 수행하기 힘들다.\n",
    "+ 인공지능의 주요 과제는 이 지식을 컴퓨터로 가져오는 것 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p7:\n",
    "+ 몇몇 인공지능 프로젝트는 형식적인 언어를 하드코딩으로 컴퓨터에 입력시켜 넣어 설명을 하는 것 처럼 보이게 만들었다. (일종의 데이터베이스)\n",
    "+ 하지만 모든 프로젝트가 실패함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p8:\n",
    "+ AI의 초기 해결 과제는 원시 데이터에서 pattern을 추출하여 그 지식을 습득하는 방법에 관한 것 이었으며, 이 기능을 기계학습(machine learning)이라고 한다.\n",
    "+ 기계학습이 발달하여 컴퓨터는 logistic regression을 이용해 제왕절개 여부를 판단할 수 있으며, naive bayes 알고리즘은 스팸 메일과 그렇지 않은 메일을 구분 할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p9:\n",
    "+ 위 예시로 든 기계학습 들은 제공된 데이터의 representation에 크게 좌우된다.\n",
    "+ AI는 환자를 직접 검사하지 않는다.\n",
    "+ 의사가 데이터를 정리하여 컴퓨터에게 제공해야 하며, 이 작업이 feature 추출이라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p10:\n",
    "+ 인간은 산술 연산을 할 때 로마 숫자 보다 아라비아 숫자를 훨씬 쉽게 한다.\n",
    "+ 마찬가지로 representation의 선택이 기계학습 알고리즘의 성능에 막대한 영향을 미친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p10:\n",
    "+ 해결하려는 작업에 따라 어떤 feature 세트를 추출 할 것 인지 달라진다.\n",
    "+ 예를 들어 목소리로 남자, 여자를 판별할 때 성량을 기초로 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p11:\n",
    "+ 하지만 어떤 feature를 추출 할 것 인지 선택 하는 것은 어려운 작업이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p12:\n",
    "+ 단순히 주어진 feature들만을 가지고 판단하는 것이 아닌, 스스로 representation 자체를 찾는 것을 **representation learning** 라고 한다.\n",
    "+ 종종 손으로 작업 한 것보다 효과적이지만, 시간을 많이 소모 해야 한다.(컴퓨팅 시간)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p13:\n",
    "+ 대표적인 representation learning 으로는 **Autoencoder** 가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p14:\n",
    "+ feature를 학습하기 위해서는 관측된 데이터를 설명하는 factor를 분리 해야한다.\n",
    "+ factor는 단순히 데이터를 구분할 수 있는 원천을 설명하는 것 이다.\n",
    "+ 음성 녹음을 분석 할 때 factor로는 화자의 연령, 성별, 억양 및 말하는 단어가 포함될 수 있다. \n",
    "+ 자동차 이미지를 분석 할 때 factor로는 자동차의 위치, 색상 및 태양의 각도 및 밝기가 포함된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p15:\n",
    "+ 실제로 컴퓨터가 데이터에서 factor를 뽑아 내기에는 많은 잡음 요소가 있어서 힘든 작업이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p16:\n",
    "+ 또한, 인간이 보기에 컴퓨터가 추출한 Factor의 수치적 차이가 얼마 나지 않으면 factor의 분류가 잘 되지 않았다고 생각 할수 도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p17:\n",
    "+ deep learning은 내부에서 단순한 concept들을 이용해 새로운 concept들을 만들 수 있으며 이러한 과정으로 모델 자신만의 factor를 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p18:\n",
    "+ deep learning의 예로는 MLP (Multilayer Perceptron)가 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p19:\n",
    "+ 딥러닝에 대한 다른 관점은 multi-step computer program 을 배운다는 것 이다.\n",
    "+ multi-step computer program의 특징은 이전의 계산 결과가 계속 반영이 되는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p20:\n",
    "+ 모델 깊이 측정에는 두 가지 방법이 있다.\n",
    "+ 첫 번째 방법으로는 순차 명령어 수 기반이며, MLP의 층 별로 나눌 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p21:\n",
    "+ 두 번째 방법으로는 concept의 관계에 따라 나눌 수 있다.\n",
    "+ 각 concept representation을 계산 하는 과정이 더 깊을 수도 있다.\n",
    "+ 예를 들어 얼굴인식의 경우 눈 인식 -> 얼굴 인식의 2 단계로 나눌 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p22:\n",
    "+ 두 방법 중 어느 것이 정답이라고 할 수는 없다.\n",
    "+ 깊다 라는 기준도 사실상 명확하게 정의되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p23:\n",
    "+ 요약\n",
    "+ 머신 러닝은 복잡한 실제 환경에서 작동 할 수있는 AI 시스템을 구축 할 수있는 유일한 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Who Should Read This Book?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1:\n",
    "+ 딥러닝 연구자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p2:\n",
    "+ 책의 구조 설명\n",
    "+ 1부 : 수학 지식, 2부 : 확립된 딥러닝 기술, 3부 : 향후 중요해질 아이디어들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p3:\n",
    "+ 왠만하면 넘기지 말고 다 보는 것을 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4:\n",
    "+ 독자가 기본 컴퓨터 지식이 있다고 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Historical Trends in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1:\n",
    "+ 딥러닝은 깊은 역사를 가지고 있으며, 초기에는 단순 철학적 요소로만 사용 되었지만, 데이터의 증가로 한번 전성기를 이루었고, 다시 컴퓨팅 파워의 증가로 한번 더 전성기를 이루었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p2:\n",
    "+ 1940년도에는 별로 인기가 없었으며, 단순 철학적으로만 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p3:\n",
    "+ 1940-1960년도 까지는 cybernetics 라고 불림\n",
    "+ 1980-1990년도 까지는 connectionism 라고 불림\n",
    "+ 2007년 부터 deep learning이라 불림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4:\n",
    "+ 현재의 인공지능 알고리즘은 뇌를 본따 만들었으며, 이를 artificial neural networks (ANNs) 이라 불렀다.\n",
    "+ 딥 러닝에 대한 신경학적 시각은 두뇌의 원리를 이해할 수 있는 도구로써 활용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p5:\n",
    "+ 현재의 딥 러닝은 신경학적으로 뇌를 모사하는 것과 관련이 깊지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p6:\n",
    "+ cybernetics\n",
    "+ n 개의 입력벡터 X 와 가중치 벡터 W $${X} = x_1, ..., x_n$$ $${W} = w_1, ..., w_n$$ 를 단순히 곱하는 것으로 계산 $$f({X},{W}) = x_1w_1 + ... + x_nw_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p7:\n",
    "+ 인공뉴런의 초기 모델\n",
    "![image1](img/image1.png)\n",
    "+ 가중치 추가\n",
    "![image2](img/image2.png)\n",
    "+ adaptive linear element (ADALINE) 개념으로 오차가 최소화 되도록 가중치를 업데이트\n",
    "![image3](img/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p8:\n",
    "+ ADALINE 은 **stochastic gradient descent**방식으로 사용 가중치를 조정함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p9:\n",
    "+ $$f({X},{W})$$ 기반의 모델을 선형 모델이라 불림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p10:\n",
    "+ 단순 선형 모델단점이 존재하며, 대표적으로 XOR 학습을 못하는 문제가 있었으며, 이로 인해 인기가 급격히 낮아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p11-p12:\n",
    "+ 신경학에서 두뇌에 대해 밝혀진게 거의 없기 때문에 많은 도움을 받을 수는 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p13:\n",
    "+ 다만 뇌는 하나의 알고리즘으로 많은 문제들을 해결하기 때문에 이 가설을 가정하면 결국 하나의 기계학습 모델이 모든 작업을 수행 할 수 있을 것 이다.\n",
    "+ 하지만 아직까지는 용도에 따라 연구 분야가 다르며, 기계학습 모델의 계산 방식에는 차이가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p14:\n",
    "+ 신경 과학 기반으로 발전한 알고리즘들이 여럿 있다.\n",
    "+ 컨볼루션 네트워크의 기초가 된 Neocognitron (Fukushima, 1980)\n",
    "+ 현대 컨볼루션 네트워크의 틀을 짠 convolutional network (LeCun et al., 1998b)\n",
    "+ 단순화한 컨볼루션 네트워크는 Nair, Hinton (2010) 와 Glorot et al. (2011a)의 논문 등에서 연구되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p15:\n",
    "+ 숙지해야 하는 것은 기계학습은 뇌를 시뮬레이션 하는 학문이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p16:\n",
    "+ 실제 뇌를 모사하는 학문은 \"computational neuroscience\"로 따로 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p17:\n",
    "+ connectionism 또는 parallel distributed processing 라는 방식으로 기계학습의 두 번째 물결이 시작됨\n",
    "+ 실제 뇌를 따라하여 뉴런을 구현하는 방식이 사용됨 (Touretzky and Minton, 1985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p18-p19:\n",
    "+ 주된 아이디어는 간단한 산술 유닛들이 네트워크를 형성하여 지능적인 동작을 달성할 수 있다는 논리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p20:\n",
    "+ 위와 같은 컨셉으로 연구된 주제 중 하나는 distributed representation 가 있다 (Hinton et al., 1986).\n",
    "+ 예를 들어 설계한 기계학습 모델이 자동차, 새, 트럭을 구분하고, 각각 녹색, 빨간색, 파란색을 알 수 있다고 가정하면\n",
    "+ 총 결과의 경우의 수는 9개 이며, 이를 위해 계산을 위한 인공 뉴런이 최소한 9개는 필요 할 것 이다.\n",
    "+ 하지만 connectionisim의 개념을 이용하면, 물체의 종류를 알기 위한 뉴런 3개와, 색깔을 알기위한 뉴런 3개로 **분할**하여 표현할 수 있다. (총 6개)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p21:\n",
    "+ connectionism의 주요 성과 중 하나는 오류역전파의 사용 (Rumelhartet al., 1986a; LeCun, 1987)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p22:\n",
    "+ 또한 시퀀스 모델에서의 적용이 어렵다는 것을 발견하고 LSTM을 제안(Hochreiter and Schmidhuber, 1997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p23:\n",
    "+ 이러한 폭발적인 성장세로 기대감이 너무 높아졌으며, 비현실적이고 야심찬 계획들이 많에 제안되었다.\n",
    "+ 하지만 당연히 대부분의 프로젝트가 실패하고 많은 사람들이 AI에 실망함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p24:\n",
    "+ 다만, 이 시기에 CIFAR에서 NCAP 연구를 제안하며, 조프리 힌튼, 조슈아 빈지오, 얀 르쿤 등이 이끄는 연구실을 통합한 그룹을 만들었으며, 다양한 기반을 마련함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p25:\n",
    "+ 결과적으로 이후 시기는 AI에 대한 불신이 많이 생기게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p26:\n",
    "+ 기계학습의 세 번째 물결은 조프리 힌튼 교수가 제안한 deep belief network(DBN)를 이용하면 효율적인 학습이 가능하다는 것을 보여준 이후였다. (Hinton et al., 2006)\n",
    "+ 위 DBN을 이용해 이전에 성능이 좋지 않았던 다른 기계학습 모델들도 테스트 하였으며 성공적인 결과를 얻고, 그 이후 다시 대중화 되기 시작한다.\n",
    "+ 14년도에 이르러 다른 AI 기술 보다 Deep Learning 기술이 효과적이란 것을 입증함 (Bengio and LeCun, 2007; Delalleau and Bengio, 2011; Pascanu et al., 2014a; Montufar et al., 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Increasing Dataset Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1:\n",
    "+ 기존 AI는 잘 짜여진 이론을 바탕으로 전문가들만이 설계할 수 있는 영역으로 간주됨\n",
    "+ 하지만 데이터의 증가로 필요 기술들이 줄어들게 되고 진입장벽이 낮아짐\n",
    "+ 가장 큰 기여는 컴퓨팅 파워의 증가\n",
    "+ **BigData**의 개념이 형성 되면서 적은 데이터에서 사용되어야 했던 고수준의 추론 기술들이 필요 없어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 Increasing Model Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1:\n",
    "+ 대규모 기계학습 모델을 학습에 사용될 계산을 감당 할 컴퓨팅 파워가 뒷받쳐 줄 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p2:\n",
    "+ 실제 생물들은 뉴런 끼리의 연결이 그렇게 조밀하게 되 있지 않음.\n",
    "+ 현재 개발 되는 뉴련의 수와 작은 포유류의 뉴런의 수는 비슷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p3:\n",
    "+ 인공뉴런의 수는 점점 증가하며, 편균 2.4년 마다 두 배씩 증가\n",
    "+ 이유는 데이터셋 증가와 컴퓨팅 파워의 증가 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4:\n",
    "+ 돌이켜보면, 뉴런의 수가 거머리의 신경세포 보다 적은 수를 지녔던 옛날 AI 모델들이 복잡한 문제를 해결 할 수 없었던 것은 당연 한 일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p5:\n",
    "+ CPU 뿐만 아니라 GPU의 발전이 기계학습의 발전을 더더욱 가속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.4 Increasing Accuracy, Complexity and Real-World Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1:\n",
    "+ 업그레이드 된 만큼 더 복잡한 문제에 적용하려 하는 시도가 일어남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p2:\n",
    "+ ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 대회에서는 12년도에 딥러닝 알고리즘이 다른 기계학습 알고리즘을 제치고 1위를 탈환 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p3:\n",
    "+ 음성인식에 적용되어 오류율이 획기적으로 떨어짐 (Dahl et al., 2010; Denget al., 2010b; Seide et al., 2011; Hinton et al., 2012a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4:\n",
    "+ 보행자 감지 성능 또한 높아졌으며, (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al., 2013)\n",
    "+ 신호등 인식은 인간을 뛰어 넘음 (Ciresan et al., 2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p5:\n",
    "+ 이미지에서 문자를 추출하는 작업이 가능하며, (Goodfellow et al. 2014d)\n",
    "+ 기계 번역으로는 혁명적인 결과를 얻음 (Sutskever et al., 2014; Bahdanau et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p6-p7:\n",
    "+ 많은 회사에서 이익을 목적으로 딥러닝을 이용함 .\n",
    "+ Google, Microsoft, Facebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA and NEC 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p8:\n",
    "+ 스스로 시행착오를 통해 주어진 작업을 수행하도록 최적화 되는 강화학습 분야에도 진출 하였으며, 아타리 게임에서 일부는 인간을 능가함(Mnih et al., 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p9:\n",
    "+ 여러 라이브러리의 성장 \n",
    "+ Theano (Bergstra et al., 2010; Bastienet al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b), DistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015), and TensorFlow (Abadi et al., 2015) 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p10:\n",
    "+ 더 많은 분야에서도 사용이 되며, 제약회사에서 약물 디자인 (Dahl et al., 2014),\n",
    "+ 원자 모형 계산 (Baldi et al., 2014),\n",
    "+ 두뇌 3차원 지도 계산에도 사용 된다.(Knowles- Barley et al., 2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. link : [신경세포의 초기모델 ADALINE](https://brunch.co.kr/@hvnpoet/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
